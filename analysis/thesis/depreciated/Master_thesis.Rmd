# Acknowlegements

<!--chapter:end:00-Acknowledgements.Rmd-->

# Introduction

The use of quantitative methods in archaeology reach back to the end of the 19th century, but it was only after the middle of the 20th century that they became computer-based. The first applications of statistical-mathematical methods using computers revolutionized the handling of spatial and quantitative archaeological data (e.g. Goldmann 1979) and also the view on archaeology itself (e.g. Clark 1968 and almost a decade later Hodder and Orton 1976, Ihm and Zimmermann 1978 to begin with). This quantitative analytical view preceded and prepared archaeologists for the advent of the public availability of soon high resolution digital datasets which revolutionized and broadened Aerial Archaeology, drawing upon the expertise of Satellite Remote Sensing and branching into a new discipline: Archaeological Remote Sensing. These new data sources, including geophysical platforms, led to the need to handle - in archaeological terms - big spatial data, thus to the specialized use of GIS platforms and the development and application of new methods like predictive modelling (van Leusen – Kamermans 2005; Kamermans et al. 2009). The sophistication of airborne platforms, sensors and imaging technologies, like LiDAR, hyper-spectral imagery and drone derived multispectral and hyper-spectral imagery (Agapiou – Lysandrou 2015; Luo et al.  2019) facilitated the diversification of the toolset of Archaeological Remote Sensing.
New technical developments continuously push specialists to look for, borrow and adapt new methods to analyse in archaeological sense big data, which first lead to automating tasks such as georeferencing or applying the same function on multiple rasters (Raun and Patterson 2018, 70). Soon this lead to more complex automation – that is automating whole workflows and also analysis. 
Thus in contrast to other disciplines, Archaeological Remote Sensing and Archaeological Science itself was quite late in adopting and applying automated methods and thus, Automated Archaeological Remote Sensing is still in its infancy (Opitz and Herrmann 2018, 30). Although accordingly, the expression ‘automated analysis’ is still controversial, it is nonetheless used throughout this Master’s thesis. It has to be emphasized that ‘automation’ does not stand for completely automated workflows. It was chosen as a short phrase to address workflows with at least partly – or mostly – automated elements, because no one advocates ‘automatic archaeology' (Cowley 2012, 6). Automated analysis, often also called semi-automated analysis, ‘simply’ means that a part, often a major part of a specific workflow, is automated, meaning computer aided. 
Critical voices about predictive modelling in GIS ˗ which can be seen as the precursor and actual starting point of automated analysis ˗ were very fittingly summarized by Wheatley 2004: predictive modelling is dehumanising, anti-historical and substitutes human actions with mathematical equations (Wheatley 2004). This distrust is reflected in the criticism towards automated analysis methods in the Archaeological and Archaeological Remote Sensing community, claiming, that archaeological projects are always locally specialized (Parcak 2009, 120) and that there is no generalized automation method that can be used location independently, which can locate atypical archaeological objects without producing a quite large miss-rate (Casana 2014, Casana 2020, S93). Taking these points into account: why only use one type of automated analysis method (Davis 2019, 5)? Large-scale landscapes feature lots of different landscape forms and archaeological features which  need to be addressed in different ways. It is evident that it is not possible to detect everything with one analysis method or algorithm, due to the variability of the archaeological record. Other considerations include reflections on Automated Archaeological Remote Sensing detecting round and square shapes over and over and when it will move to something more useful that actually resembles archaeological objects (Rog Palmer in personal discussion and several AARGnews Editorials and contributions, e.g. AARGnews 62, 61)? 
It is also somehow self-evident, that although pre-trained and known object classes are going to be detected, new and unexpected and also not detected objects always have to be expected. Thus expecting to detect unexpected or unknown object classes with supervised learning/automation is misleading and completely unrealistic (see a similar discussion about the use of predictive modelling in Wheatley 2004, 3.2.3). It is a fatal move to expect automation to be the magic trick, when it is not: it should be more seen as an extension of the archaeologist’s toolbox. Because automated analysis is not to replace manual data evaluation which, based on the personal experience of the operator and them being human, can be prone to missing knowledge or error, or even archaeologists completely, but to be complementary. Automated analysis should be followed by field observation and identification for assessment, which on the other hand also can be biased for the same reason as manual data evaluation (Cowley 2012, Bennett et al 2014, 899). All in all automated analysis is to ease and facilitate the amount of work archaeologists are facing with the increasing amount of data and different data types to analyse and evaluate. As Davis (2020a, 3) emphasizes: automated analysis is precise and manual analysis is accurate. Thus both methods combined can help archaeologists to penetrate a hidden level of any dataset and landscape, which is invisible or hardly visible even for the trained eye.
Taking it further, reproducible analysis (Marwick 2017, Rokem et al. 2017, Marwick et al. 2018, Calero Valdez 2020) can help to facilitate automated analyses and can serve as control for human individuality: because archaeologists do see different things in the same data set and unconsciously see what they are familiar with and what they know (Cowley 2012, 7), very similarly to an algorithm trained to find a certain class of object. Human detection cannot be reproduced but automated analysis can: via documented, reproducible workflows. In order to achieve this goal open-source scripting languages like R, Python or open-source platforms like Google Engine should be used, to be able  to repeat, reproduce and even replicate workflows to facilitate their use by other scholars. When writing code, the semantic syntax has to be clear and consistent. This also makes sure that the ontology and the semantic syntax will be the same when the code is used by a different operator on a different dataset – in contrary to manual analysis, where independent, subjective manual operators would define features or objects differently – thus arriving to the same or a least similar bias and errors, of course depending on the dataset. This argument is investigated more thoroughly in chapter III and the expressions reproducible and replicable are discussed in more detail.

Being entirely different disciplines, there is a semantic gap between the ontologies of Computer Vision, Image Analysis and Remote Sensing on one hand and Archaeology on the other hand – especially because the archaeological record itself is fragmented, multifaceted and poses ontological problems in itself for the interoperability of projects or databases, conducted by different operators with possible different metalanguage. Although the aim of this thesis is not the creation of an ontological and semantic framework and/or a metalanguage for Automated Archaeological Remote Sensing, these points have to be discussed because they affect the way how automation can be harmonized with Archaeological Remote Sensing.  
This fundamental difference is reflected in the fact, that a distinction has to be made between ‘object’ and ‘feature’ in sensu stricto automation, based on termini technici from Computer Vision, on which ground ‘object’ is referred to real-world entities in remote sensing images and ‘feature’ to elements of an image and of an object (Traviglia et al. 2016, 12;  Lambers et al 2019, 2), in contrary to the every-day use of the expression ‘archaeological feature’ at an excavation site or in reports. Reproducible code and workflows enable to conduct the same ‘procedure’ in a controlled environment and thus possible semantic problems which can result from how different operators see archaeological objects and features can be detected, distinguished and solved. Thus the accurate expert knowledge of manual analysis can be integrated in the precision and consistency of computational semantics (Davis 2020a, Fig 1.). 

```{r Figure 1, echo=FALSE, fig.align='center', out.width="50%", out.height="50%", fig.cap="Chart showing the advantages (approaching Semantic Consistency) when Expert Knowledge, Manual Analysis and Automated analysis are combined. Source: Davis 2020a, Fig 1."}
knitr::include_graphics('C:/Users/kelto/Documents/iSEGMound/analysis/figures/Figure_1.png')
```

On the other hand, manual analysis can learn a lot from the systematic precision of reproducible code: defining variables, consistent nomenclature of objects/ forms/ features; creating functions: setting the relation of objects/ forms/ features. This needs the consistency of formalized, straightforward and clear definitions (also Magnini and Bettineschi 2019, 13, Davis 2020a). Thus ontology, semantics and metadata are very important tools which enable us to connect and share code, databases and research. By shared ontologies (knowledge representation), codified metalanguage protocols and rule-sets, not only would the transferability of expert knowledge be substantially eased between Archaeological disciplines and Automated Archaeological Remote Sensing, but also between its different subdisciplines, like Template Matching-, Geometric knowledge-, GeOBIA-, Machine Learning- based analyses (this distinction is explained in chapter 2).

So then, after all, how to semantically address the varying, unpredictable, fragmented, multifaceted and diachronic archaeological record (monuments and artefacts) which can be detected in remote sensing data with methods of Computer Vision and Image Analysis? Remote sensing data offers much more: they are diachronic time capsules, records of palimpsest landscapes, archaeological, micro- and macro-topographical, geomorphological and also recent, anthropomorphic traces (Magnini and Bettineschi 2019, 12) in a multidimensional space. Thus a common ground has to be created (a shared diachronic formalized ontology) to fill the semantic gap between the metalanguage of human perception, the archaeological record (which is manifold, imbalanced and changing in time (conceptually and physically) and Computer Vision/Image Analysis. And a way has to be found to apply this new diachronic formalized ontology onto real world scenarios (using Automated Archaeological Remote Sensing). Real world (archaeological) scenarios are often extremely complex and thus robust simplification and formalization has to be executed to break down complexity and bring the domains in discussion together. Sevara and Pregesbauer (2014) already pioneered a conceptual framework in 2014, which found resonance and the formulation of a Diachronic Semantic Model (DSM) in Magnini and Bettineschi 2019, which was successfully applied by the latter on a case study in 2021 (Magnini and Bettineschi 2021). These fundamental studies are the first steps towards integrating Automated Archaeological Remote Sensing in the  nervous system of Archaeological Science. 

As concluding thoughts let a quote from Quintus et al. (2017, 1) state: *“many archaeological professionals who might have an interest in lidar-derived products do not have the technical experience to modify or create AFE (automated feature extraction) techniques for particular regions or environments.”* This should not impact the scientific methods one chooses. With open-source, reproducible (regularly updated and version controlled) and code, with clear replicable workflows and published data and study (at least the manuscript in a preprint repository) (Figure 3), every remote sensing archaeological professional should be able to tap into the possibilities of Automated Analysis. Thus open access and open source software should be used, training data sets and workflows released to be able to learn from each other and to progress, building on the experience of each other and not to have to start from scratch with every new project conducted. 

```{r Figure 2, echo=FALSE, out.width="75%", out.height="75%", fig.align='center', fig.cap="The difference between articles behind paywall and reproducible (and replicable) studies. Source: Marwick et al. 2017, Figure 1."}
knitr::include_graphics('C:/Users/kelto/Documents/iSEGMound/analysis/figures/Figure_2.png')
```

Thus we not only need to compare the accuracy and the true and false positive rate of different automated methods (Trier at al. 2018, Table 1) and the methods themselves (Davis et al. 2019), but we need to make a compendium of these methods with the key elements mentioned above. Combined with this, a baseline or best practice for the different methods should be defined that can be utilized by beginners. Thus open-access code, workflow and protocol, published (at least training) data sets and best practices are needed as reference and base line for other studies, stored in an open-source database or platform which can support open-source computer languages. 

Different observations made above and questions based on these have led to the objective of this thesis. Firstly: based on scientific literature, on what grounds lies the dispute of automation in Archaeological Remote Sensing and how can it be relieved? Is the experience and knowledge gained transferable to other studies? How many scientific studies on burial mound detection worked transparently and retraceable (reproducible if not replicable) in any step of their workflow? Can experiences and knowledge from previous studies be used to create a reproducible and replicable workflow for burial mound detection?  
Thus the aim of this Master’s thesis is to emphasize the applicability and usefulness of automation in dealing with big datasets in Archaeological Remote Sensing and the need for reproducible and replicable workflows and studies. The case study for this thesis is the detection of burial mounds in LiDAR datasets in R, to substantiate this point of view.

To approach these questions accordingly, after the discussion of Automated Archaeological Remote Sensing and its reception in Archaeological Science was discussed in Chapter I, the Introduction. In the next chapter (II) all published studies whose goal is to detect burial mounds or mound-like structures are discussed in terms of used methods, software, accessibility of code and data. It is also elaborated why burial mounds are chosen as Objects of Interest and which methods will be applied and why. Chapter III provides the toolbox for the thesis to implement the desiderats and requirements discussed in Chapter I and II. Chapter IV presents a reproducible workflow for the detection of burial mounds in LiDAR data. Chapter V (Discussion) and Chapter VI (Outlook) completes the endeavour of this Master’s thesis. 

<!--chapter:end:01-Intro.Rmd-->

# Exploitation of Automated Analysis Methods to detect burial mounds and structurally similar archaeological objects: a survey

The analysis carried out and communicated in this chapter reviews all published studies which are aimed at the detection of burial mound and mound-like structures in order to define a baseline to place present research. Numerous reviews of methods and applications used in Archaeological Remote Sensing have been carried out (e.g. Leisz 2013, Agapiou and Lysandrou 2015; Davis 2018, Luo et al. 2019, Fiorucci et al. 2020): some broad and general, some more specific. The word survey was chosen specifically, because it was not a systematic search of databases as various ‘classical’ reviews did (such as Agapiou and Lysandrou 2015, Raun and Patterson 2018, Magnini and Bettineschi 2019 and Davis 2020a & b). 
This survey is building on the experience of aforementioned systematic reviews (which show very diversified nomenclature and heterogeneous terms) and the scientific literature was collected based on these reviews, Researchgate, Academia and mainly considering open-access publications (if possible). As a starting point all published studies (at least available to the author via University access; number of studies in August 2021: 96) have been collected which deal with the automation of Archaeological Remote Sensing data set (practical studies which use any automation methods and analysis) but only those are discussed, which are concerned with the detection of burial mounds and structurally similar archaeological objects: altogether 31 publications. Burial mounds have been chosen as Objects of Interest for the review because they are relatively simple structures and a very common funerary custom throughout human history. Similarly structured archaeological objects like tell mounds or other monumental earthworks of circular form can be found in very different areas and time periods and are widely investigated and thus deliver good examples of automated analysis methods of these archaeological objects. The first archaeological objects to automatically detect were tell mounds and only then and with the dawn of the use of LiDAR data came burial mounds into the focus of research. While the early research carried on tell settlements can be connected to Ur & Menze, the monumental earthworks and mound shell rings can also be allocated to two research groups: Freeland et al. and Davis, Lipo & Sanger. The detection of burial mounds themselves shows more variability in the investigators (Figure 3). A complete list of references (which is by far not conclusive and is to be supplemented) is included as a supplement at the end of this thesis. 

```{r Figure 3, echo=FALSE, fig.align='center', fig.cap="The Objects of Interests investigated by year between 2006 and 2021."}
library(dplyr)
library(ggplot2)
mounds_lit_2 <- read.csv(here::here('analysis/data/literature_analysis/burial_mounds_short.csv'))
#read as tibble
mounds_lit_2 <- dplyr::as_tibble(mounds_lit_2)
mounds_lit_2_filt <- mounds_lit_2[, c(3:7)]
all_combined_2 <- table(mounds_lit_2_filt$Year, mounds_lit_2_filt$OoI,
                      mounds_lit_2_filt$Data, mounds_lit_2_filt$Software_type,
                      mounds_lit_2_filt$access)
methods_table_2 <- stats::ftable(all_combined_2)
methods_table_df2 <- as.data.frame(methods_table_2)
names(methods_table_df2) <- c("Year", "OoI", "Data", "Software_type", "access", "Freq")
ggplot(methods_table_df2, aes(fill=OoI, y=Freq, x=Year)) +
  geom_bar(position="stack", stat="identity") +
  ylim(0, 7) +
  scale_fill_manual(values=morris:::holland_palette) +
  ggtitle(expression(atop("Objects of Interest in Automated Archaeological Remote Sensing", atop("between 2006 and 2021", "")))) +
  theme_light() +
  xlab("Year") +
  ylab("Number of studies")
```
The main points considered in this survey were chosen based on the aforementioned reviews, which were conducted looking at citation indexes of different Remote Sensing methods in scientific periodicals (Agapiou and Lysandrou 2015, Raun and Patterson 2018, Luo et al. 2019, Davis 2020b), Institutional Affiliations of researchers (Agapiou and Lysansrou 2015, Raun and Patterson 2018), the citation network (Raun and Patterson 2018), OBIA by geographic region (Davis 2018), the developments and limitations of OBIA methods (Davis 2018), research goal using OBIA (Davis 2018), the development of different passive and active Remote Sensing methods (Luo et al. 2019), the scale of ArchaeOBIA applications (Magnini and Bettineschi 2019), datasets and methods applied in Archaeological Remote Sensing (Fiorucci et al. 2020), different parameters, thresholds, methods and accuracy used in the automated detection of mound features (Davis 2020a) and geometric disparity of Remote Sensing methods (Davis 2020b). 
These systematic reviews stimulated questions such as: How can we learn from previous studies? How transparent is the workflow and if described, which variables and parameters (rule sets) were used? Which software was used? How reproducible or even replicable is the workflow in the studies? 

Based on these questions the points investigated in this Master’s thesis are: 

(i) Location (only in Supplement 1)
(ii) RS (Remote Sensing) data
(iii) Methods
(iv) Detail of methods (only in Supplement 1)
(v) Variables/morphometric parameters
(vi) OoI (Objects of Interest)
(vii) Scale
(viii) Software
(ix) Access 

The point “Location” (i) was documented, because different geographical and landscape conditions ask for different methods and objects can appear geographically and culturally diverse, which can explain the chosen method. The point “RS data” (ii) documents which type of remote sensing data was used and also it’s resolution if known. The point “Methods” (iii) organizes the studies in five main categories (Template Matching, Geometric Knowledge-based, GeOBIA-based and Machine Learning-based, Deep Learning; see Figure 4), based on Cheng and Han 2016 (also see Lambers et al. 2019 and Roffler 2020), instead of juxtaposing pixel-based and object-based methods. This differentiation points out the different object detection methods based on the approach to the dataset. Still, for the differentiation of Machine Learning-based methods, the expression pixel-based is going to be used for the classifier training-based methods, also because several studies use it (Sevara et al. 2016, Niculită 2020b). 

```{r Figure 4, echo=FALSE, fig.align='center', out.width="50%", out.height="50%", fig.cap="Taxonomy of Automated Analysis in Archaeological Remote Sensing, based on Cheng and Han 2016."}
knitr::include_graphics('C:/Users/kelto/Documents/iSEGMound/analysis/figures/Figure_4.png')
```
The point “Details of method” (iv) explains the workflow of the study in a nutshell, if comprehensible. Point v, “Variables/Morphometric parameters” highlights the variables and or morphometric parameters used in the study. “OOI” (vi) are the objects investigated. The point “Scale” (vii) implies the geographical range of the study, if it was applied to a broader region than the area on which the method was developed. The last two points (“Software” - viii, and “Access” - ix) investigated give us hints about the accessibility of the dataset and the code. Especially in earlier studies, information about the software used is not mentioned and sometimes can only be guessed. In the case of “Access”, apart from the information about accessible data and code it was also documented if there is a workflow (a comprehensible sequence of the steps of the workflow) or a flowchart (a very generalized workflow without clear steps) or if any of the equations used was published and or explained. It was also documented if any supplementary information or document was attached to the study which can guide to a better understanding for a possible reproduction of the study. Although all these points have been investigated, for practical reasons mainly the points (ii) RS (Remote Sensing) data, (iii) Method/s, (iv) Detail of method/s, (v) Variables/morphometric parameters, (vi) OoI/Object(s) of Interest, (viii) Software and (ix) Access is going to be elaborated in depth in this and the next chapter. 

It is essential to discuss the basic traits of the used methods (iii) in short, concentrating on their application in Archaeological Remote Sensing. It has to be stressed, that still no semantic lingua franca (between Archaeological Remote Sensing and Computer Vision and Remote Sensing Methods) exists when talking about automated methods in Archaeological Remote Sensing, thus methods are addressed in different ways (or most commonly in a very simplified way) and it is not always possible to determine which exact method has been utilised (recently it is improving, but it depends where the authors put the focus of their work). First, when shortly discussing the basic traits of the methods and their use in Archaeological Remote Sensing, it is only focussed on the use of the different methods (what is used, where and when) since 2006, when tell mounds were first investigated using automated analysis methods. In the second part of this chapter the way of their use is investigated and analysed how the methods are used. 

***Template Matching-based methods*** utilize a template of the Object of Interest to be detected, which is then statistically matched to the input image. Two general directions can be distinguished: Rigid Template Matching, which requires a precise template which gets problematic when it comes to intra-class shape and size variations. Deformable Template Matching on the other hand can handle either free-form deformable templates or parametric deformable templates. (Cheng and Han 2016, 13-14).
In the literature investigated Template Matching was used seven times for the detection of burial mounds, mound shell rings and tell mounds (De Boer 2007, Kramer 2015, Trier et al. 2015, Davis et al. 2018, Raun 2019, Davis et al. 2019, GholamReza and Malian 2021). Apart from Kramer 2015, Rigid Template Matching was preferred (Table 1). Template Matching itself is a method which is being revisited from time to time (Figure 5).

```{r Figure 5, echo=FALSE, fig.align='center', out.width="75%", out.height="75%", fig.cap="The Objects of Interests investigated by year between 2006 and 2021."}
library(dplyr)
library(ggplot2)
mounds_lit <- read.csv(here::here('analysis/data/literature_analysis/burial_mounds.csv'))
#read as tibble
mounds_lit <- dplyr::as_tibble(mounds_lit)
mounds_lit_filt <- mounds_lit[, c(3:7)]
all_combined <- table(mounds_lit_filt$Year, mounds_lit_filt$OoI, mounds_lit_filt$Method,
                      mounds_lit_filt$Data, mounds_lit_filt$Software_type)
all_combined_table <- stats::ftable(all_combined)
all_combined_df <- as.data.frame(all_combined_table)
names(all_combined_df) <- c("Year", "OoI", "Method", "Data", "Software_type", "Freq")
methods <- table(mounds_lit_filt$Year, mounds_lit_filt$Method)
methods_table <- stats::ftable(methods)
methods_table_df <- as.data.frame(methods_table)
names(methods_table_df) <- c("Year", "Method", "Freq")
names(methods_table_df)
TM <- methods_table_df %>% filter(Method=="Template Matching")
ggplot(TM, aes(x=Year, y=Freq)) +
  geom_bar(stat="identity", fill ="#A68A59") +
  ylim(0, 5) +
  ggtitle("Use of Template Matching-based methods between 2006 & 2021") +
  theme_light() +
  theme(legend.position="center") +
  xlab("Year") +
  ylab("Number of studies")
```
***Geometric knowledge-based analysis*** works with specialized solutions for specific problems, applying rules based and established on knowledge of the regions of interest and it’s context. It uses either encoded prior geometric knowledge of the generic specificity of the Object of Interest and then e.g. applies hand-crafted mathematical morphometry rules for object extraction (morphometric derivatives such as Slope, Aspect, Curvature, Local Relief Model, vegetation indices etc.). Context knowledge based analysis uses knowledge about the relationship of the Object of Interest and the area it should be separated from (e.g. filters, textural analysis) (Cheng and Han 2016, 15). In the case of Automated Archeological Remote Sensing the two Geometric knowledge-based analysis approaches are often used in combination and form the data preparation step (Figure 6). Geometric knowledge based object analysis is only occasionally used per se as an automated analysis method for the detection of burial mounds, monumental earthworks and tell mounds: Riley 2009, Freeland et al. 2016, Rom et al. 2020. (Lately) it is only occasional, that Geometric knowledge-based object analysis is not used as data preparation method (De Boer 2007, Caspari et al. 2014, Trier et al. 2015, Raun 2019, Caspari and Crespo 2019, Kazimi et al. 2019a, Kazimi et al. 2019b). In some cases, Geometric knowledge based analysis is included in the future work (compare works by Kazimi et. al 2019 vs. Kazimi et al. 2020)(Table 1.).  

```{r Figure 6, echo=FALSE, fig.align='center', out.width="75%", out.height="75%", fig.cap="The use of Geometric knowledge-based methods distributed by year between 2006 and 2021."}
library(dplyr)
library(ggplot2)
mounds_lit <- read.csv(here::here('analysis/data/literature_analysis/burial_mounds.csv'))
#read as tibble
mounds_lit <- dplyr::as_tibble(mounds_lit)
mounds_lit_filt <- mounds_lit[, c(3:7)]
all_combined <- table(mounds_lit_filt$Year, mounds_lit_filt$OoI, mounds_lit_filt$Method,
                      mounds_lit_filt$Data, mounds_lit_filt$Software_type)
all_combined_table <- stats::ftable(all_combined)
all_combined_df <- as.data.frame(all_combined_table)
names(all_combined_df) <- c("Year", "OoI", "Method", "Data", "Software_type", "Freq")
methods <- table(mounds_lit_filt$Year, mounds_lit_filt$Method)
methods_table <- stats::ftable(methods)
methods_table_df <- as.data.frame(methods_table)
names(methods_table_df) <- c("Year", "Method", "Freq")
names(methods_table_df)
GKNB <- methods_table_df %>% filter(Method=="Geometric knowledge")
ggplot(GKNB, aes(y=Freq, x=Year)) +
  geom_bar(stat="identity", fill ="#70795E") +
  ylim(0, 7) +
  ggtitle("Use of Geometric knowledge-based methods between 2006 & 2021") +
  theme_light() +
  theme(legend.position="none") +
  xlab("Year") +
  ylab("Number of studies")
```
***Geographical Object-based Image Analysis (GeOBIA)*** dates back to the late 1970’s (Blaschke et al. 2014), but it was only around 2000 that Object-based Images Analysis became widely used in Remote Sensing studies due to the availability of high resolution Satellite data. This induced a paradigm shift not only in Remote Sensing but generally in GI Science, hence its new name: GeOBIA (Hay and Castilla 2008). GeOBIA operates in two steps: images are divided into small segments, which are defined by the homogeneity of specific morphometric (shape, size, orientation), spectral, textural, context and neighborhood parameters (Hay – Castilla 2008) and are then grouped together to meaningful homogeneous object candidates (the segmentation step), which are then classified by specific extracted object criteria in question (the feature extraction and classification step, Blaschke et al. 2014, 186, Cheng and Han 2016, 15, Hossain and Chen 2019, 115) or filtered by a rule-set. Various types of segmentation methods exist (as also their categorization: Blaschke 2010, Blaschke et al. 2014, Kumar et al. 2014). Lately Hossain and Chen 2019 investigated the different segmentation methods from a Remote Sensing point of view, but here only the two main Segmentation methods used in Automated Archaeological Remote Sensing studies are described: Watershed Segmentation (or Transformation) (Niculiță 2020a,b) and Multiresolution Segmentation (Kramer 2015, Sevara et al. 2016, Freeland et al. 2016, Davis et al. 2018,  Davis et al. 2019, Meyer-Heß et al. 2019, Sărășan et al. 2020), the first being an Edge-Based Segmentation method, the latter a Region-Based Segmentation method. For an in-depth analysis see Hossain and Chen 2019. 

*Edge-Based Segmentation techniques* are ‘top-down’ methods: first they locate edges in the image and then use contouring algorithms to close them. Edges are regarded as boundaries between objects where pixel properties are abruptly changing (Hossain and Chen 2019, 117). ‘Watershed Segmentation’ (implemented in open source software e.g. in SAGA or in the ForestTools package in R) simulates real-life flooding. It first transforms the image into a gradient (grey-scale), then identifies objects with clear segment boundaries, only to then create (fill) objects, for which it is also called a Region-Growing algorithm (Hossain and Chen 2019, 117, Table 1; Figure 7). 

```{r Figure 7, echo=FALSE, fig.align='center', fig.cap="Operating principle of ‘Watershed Segmentation’. Roffler 2020, 33."}
knitr::include_graphics('C:/Users/kelto/Documents/iSEGMound/analysis/figures/Figure_7.png')
```
Region-Based Segmentation techniques start from the complete opposite: they begin with an initial segmentation of the whole image (thus also called ‘bottom-up methods’) based on a specific rule-set. Regions are generated in two completely different ways: either by splitting the image into homogeneous regions based on inhomogeneity (region-splitting and then merging) or by region-growing from a so-called seed-region based on homogeneity (region-growing and then merging, Hossain and Chen 2019, 119). ‘Multiresolution Segmentation’ (Baatz and Schäpe 2000, for which mainly eCognition is used in Automated Archaeological Remote Sensing) is a region-merging hierarchical segmentation method which starts with one pixel (seed) and applies pairwise merging of segments to build up hierarchical levels. The merging – or clustering (using local rule sets) is repeated (on multiple levels), until an object is recognized (Hossain and Chen 2019, 119, Roffler 2020, 33-34; Figure 8). 

```{r Figure 8, echo=FALSE, fig.align='center', out.width="75%", out.height="75%", fig.cap="Operating principle of ‘Region Growing Segmentation’. Roffler 2020, 34."}
knitr::include_graphics('C:/Users/kelto/Documents/iSEGMound/analysis/figures/Figure_8.png')
```

With regard to (Automated) Archaeological Remote Sensing, GeOBIA is sometimes also called archaeOBIA (Lamotte and Masson 2016), which points to the fact, that (Automated) Archaeological Remote Sensing is in need of a completely different semantic ontology and rule sets than which is needed for customary GeOBIA methods used in Remote Sensing. Still recently the challenge in Remote Sensing has been to define segmentation parameters/rule sets which can be transferred to other images (Cheng and Han 2015, 16) – something archeOBIA is also struggling with (see Table 1; note the different variables used in the different studies).
Burial mounds, monumental earthworks and mound shell rings have been investigated using GeOBIA methods nine times since 2015 (Figure 9). Apart from one case (Niculiță 2020: Watershed Segmentation, carried out with SAGA in R), Multiresolution Segmentation was applied (Table 1), almost exclusively using eCognition, (former Definiens), a software developed for and with the evolution of GeOBIA and thus is generally considered “the software” for GeOBIA (Blaschke 2010, Fig 4, Hossain and Chen 2019, Fig 1.), which is clearly reflected in this survey. 

```{r Figure 9, echo=FALSE, fig.align='center', out.width="75%", out.height="75%", fig.cap="The use of GeOBIA methods distributed by year between 2006 and 2021."}
library(dplyr)
library(ggplot2)
mounds_lit <- read.csv(here::here('analysis/data/literature_analysis/burial_mounds.csv'))
#read as tibble
mounds_lit <- dplyr::as_tibble(mounds_lit)
mounds_lit_filt <- mounds_lit[, c(3:7)]
all_combined <- table(mounds_lit_filt$Year, mounds_lit_filt$OoI, mounds_lit_filt$Method,
                      mounds_lit_filt$Data, mounds_lit_filt$Software_type)
all_combined_table <- stats::ftable(all_combined)
all_combined_df <- as.data.frame(all_combined_table)
names(all_combined_df) <- c("Year", "OoI", "Method", "Data", "Software_type", "Freq")
methods <- table(mounds_lit_filt$Year, mounds_lit_filt$Method)
methods_table <- stats::ftable(methods)
methods_table_df <- as.data.frame(methods_table)
names(methods_table_df) <- c("Year", "Method", "Freq")
names(methods_table_df)
GeOBIA <-methods_table_df %>% filter(Method=="GeOBIA")
ggplot(GeOBIA, aes(y=Freq, x=Year)) +
  geom_bar(stat="identity", fill ="#A9AF86") +
  ylim(0, 5) +
  ggtitle("Use of GeOBIA methods between 2006 & 2021") +
  theme_light() +
  theme(legend.position="none") +
  xlab("Year") +
  ylab("Number of studies")
```
***Machine Learning-based methods*** are considered a subfield of Artificial Intelligence. Machine learning automates statistical methods to learn from input data either supervised, unsupervised or semi-supervised. Automated Archaeological Remote Sensing mainly utilizes supervised methods.
*Pixel-based Image Analysis*, an image classification method, has been developed in the early 1970s for the digital analysis of Landsat Multispectral Scanner Systems (Phiri and Morgenroth 2017, 9) and is (still) widely distributed in Remote Sensing research, especially in land-use and land-cover classification. In contrast to GeOBIA, Pixel-based Image Analysis approaches an image on pixel basis, which are classified into different categories based on the information they carry (usually one variable). Given that the second step of GeOBIA can be a classification of the segmented image using variables of the image-objects best describing the Objects of Interest, GeOBIA is sometimes also seen as a form of Machine Learning (Davis 2018, 1). 
Random forest classifiers are supervised learning algorithms which consist of an ensemble of decision trees. Each (unrelated) decision tree is trained using a random subset of the training data. Each of these trees will give a prediction for a datapoint. Then, the prediction of all decision trees is averaged by a majority vote to a final prediction (Figure 9). The independence of the different decision trees increases the accuracy of the prediction and also eliminates problems that can be caused by outliers in the dataset and works also well with small datasets, because of the facts just explained. These effects can be enhanced by resampling techniques and parameter tuning (Kuhn and Johnson 2016). 

```{r Figure 10, echo=FALSE, fig.align='center', out.width="50%", out.height="50%", fig.cap="Schematized modus operandi of the Random Forest algorithm."}
knitr::include_graphics('C:/Users/kelto/Documents/iSEGMound/analysis/figures/Figure_10.png')
```
Regarding the automated detection of burial mounds and similar structures, Pixel-based classification was the first method used in 2006 and has been more or less revisited since (Figure 11). When looking closely at the specific algorithms used, it is not surprising why the Random Forest algorithm was exploited in most Pixel-based Image Analysis studies (Menze et al. 2006, 2007, Menze and Ur 2007, 2012, 2013, Kramer 2015, Guyot et al. 2018, Orengo et al. 2020, Niculiță 2020, Davis et al. 2021) and Mahalanobis Distance (Trier et al. 2015, Severa et al. 2016) and Support Vector Machine Classifiers (Caspari and Crespo 2019) in less.

```{r Figure 11, echo=FALSE, fig.align='center', out.width="75%", out.height="75%", fig.cap="The use of Pixel-based Image Analysis methods distributed by year between 2006 and 2021."}
library(dplyr)
library(ggplot2)
mounds_lit <- read.csv(here::here('analysis/data/literature_analysis/burial_mounds.csv'))
#read as tibble
mounds_lit <- dplyr::as_tibble(mounds_lit)
mounds_lit_filt <- mounds_lit[, c(3:7)]
all_combined <- table(mounds_lit_filt$Year, mounds_lit_filt$OoI, mounds_lit_filt$Method,
                      mounds_lit_filt$Data, mounds_lit_filt$Software_type)
all_combined_table <- stats::ftable(all_combined)
all_combined_df <- as.data.frame(all_combined_table)
names(all_combined_df) <- c("Year", "OoI", "Method", "Data", "Software_type", "Freq")
methods <- table(mounds_lit_filt$Year, mounds_lit_filt$Method)
methods_table <- stats::ftable(methods)
methods_table_df <- as.data.frame(methods_table)
names(methods_table_df) <- c("Year", "Method", "Freq")
names(methods_table_df)
PBIA <-methods_table_df %>% filter(Method=="PBIA")
ggplot(PBIA, aes(y=Freq, x=Year)) +
  geom_bar(stat="identity", fill ="#BCC0AF") +
  ylim(0, 5) +
  ggtitle("Use of PBIA methods between 2006 & 2021") +
  theme_light() +
  theme(legend.position="none") +
  xlab("Year") +
  ylab("Number of studies")
```
It was already suggested that with the development of remote sensing sensors and resulting new, higher resolution datasets the need for new analysis methods is constantly stimulated. Starting with pixel-wise analysis and followed by the object-level addressing of remote sensing imagery, lately an even bigger semantic step was taken: the analysis on the scene-level, which can be seen as the next paradigm shift (Cheng and Han 2016, Cheng et al. 2020, 2, Fig. 2). The complex semantic structures of very high resolution images are addressed by  *Deep Learning*, which is also a sub-field of Machine Learning. In contrast to Pixel- and Object-based Image Analysis, Deep Learning Algorithms consist of multiple stacked hierarchical layers (network architectures) which can handle complexity and abstraction.
In the case of the identification of burial mounds and mound like structures Deep Learning is only in use since 2019 (Figure 12). 

```{r Figure 12, echo=FALSE, fig.align='center', out.width="75%", out.height="75%", fig.cap="The use of Deep Learning methods distributed by year between 2006 and 2021."}
library(dplyr)
library(ggplot2)
mounds_lit <- read.csv(here::here('analysis/data/literature_analysis/burial_mounds.csv'))
#read as tibble
mounds_lit <- dplyr::as_tibble(mounds_lit)
mounds_lit_filt <- mounds_lit[, c(3:7)]
all_combined <- table(mounds_lit_filt$Year, mounds_lit_filt$OoI, mounds_lit_filt$Method,
                      mounds_lit_filt$Data, mounds_lit_filt$Software_type)
all_combined_table <- stats::ftable(all_combined)
all_combined_df <- as.data.frame(all_combined_table)
names(all_combined_df) <- c("Year", "OoI", "Method", "Data", "Software_type", "Freq")
methods <- table(mounds_lit_filt$Year, mounds_lit_filt$Method)
methods_table <- stats::ftable(methods)
methods_table_df <- as.data.frame(methods_table)
names(methods_table_df) <- c("Year", "Method", "Freq")
names(methods_table_df)
DL <-methods_table_df %>% filter(Method=="Deep Learning")
ggplot(DL, aes(y=Freq, x=Year)) +
  geom_bar(stat="identity", fill ="#43595E") +
  ylim(0, 5) +
  ggtitle("Use of Deep Learning methods between 2006 & 2021") +
  theme_light() +
  theme(legend.position="none") +
  xlab("Year") +
  ylab("Number of studies")
```
To summarize the use of automated analysis methods to detect burial mounds and mound-like structures (Figure 13), it can be established that the first method used was Pixel-based Image analysis (Menze et al. 2006), followed by Template Matching (de Boer 2007). Geometric knowledge-based analysis was used as an autonomous method only by Riley 2009, Freeland et al. 2016, Rom et al. 2020, but as already concluded it is more often than not incorporated in workflows as data preparation method. GeOBIA was first used in 2015 and remained a very effective analysis method, until recently when Deep Learning became widespread (including Semantic and Instance Segmentation).

```{r Figure 13, echo=FALSE, fig.align='center', out.width="75%", out.height="75%", fig.cap="The use of different Image Analysis methods to detect mounds and mound-like objects distributed by year between 2006 and 2021. Note: this represents the number of methods used, not the number of studies."}
library(dplyr)
library(ggplot2)
mounds_lit <- read.csv(here::here('analysis/data/literature_analysis/burial_mounds.csv'))
#read as tibble
mounds_lit <- dplyr::as_tibble(mounds_lit)
mounds_lit_filt <- mounds_lit[, c(3:7)]
all_combined <- table(mounds_lit_filt$Year, mounds_lit_filt$OoI, mounds_lit_filt$Method,
                      mounds_lit_filt$Data, mounds_lit_filt$Software_type)
all_combined_table <- stats::ftable(all_combined)
all_combined_df <- as.data.frame(all_combined_table)
names(all_combined_df) <- c("Year", "OoI", "Method", "Data", "Software_type", "Freq")
ggplot(all_combined_df, aes(fill=Method, y=Freq, x=Year)) +
  geom_bar(position="stack", stat="identity") +
  ylim(0, 15) +
  scale_fill_manual(values=morris:::acanthus_palette) +
  ggtitle(expression(atop("Methods used in Automated Archaeological Remote Sensing", atop("between 2006 and 2021", "")))) +
  theme_light() +
  xlab("Year") +
  ylab("Number of studies")
```
Several studies compare different analysis methods or combine them. Freeland et al. 2016 and Davis et al. 2019 compare Geometric-knowledge-based analysis (iMound/Inverse Stochastic Depression Analysis) to GeOBIA, with success (this is also reflected in the fact that the original algorithm iMound by Freeland at al. 2016 was reused by Davis et al. 2019 and Rom et al. 2020). Template Matching has been compared to GeOBIA (Kramer 2015, Davis et al. 2019: including Geometric knowledge-based method) and Pixel-based Image Analysis to GeOBIA (Sevara et al. 2016) and to Deep Learning (Caspari and Crespo 2019).

Although LiDAR data has been available for some time (see De Boer 2007, Riley 2009), it was only after 2010 that it made its way into everyday archaeological research, including various visualization methods (as Geometric knowledge-based analysis and data preparation method), making LiDAR visualisations a self-evident step for any archaeological project using ALS data (see also Kokalj and Hesse 2017). It is mainly from 2015, when ALS data started to dominate and revolutionize Automated Analysis methods in Archaeological Remote Sensing and provoking new approaches, such as GeOBIA (Figure 14). Since the diffusion of LiDAR data, Satellite Imagery is mainly used in large-scale studies (Caspari and Crespo 2019, Orengo et al. 2020). Studies which require high resolution data and utilize LiDAR quickly shifted to Deep Learning solutions. Simultaneously also UAV data finds its way into the general data repertoire of Automated Archaeological Analysis (Sărășan et al 2020). 

```{r Figure 14, echo=FALSE, fig.align='center', out.width="75%", out.height="75%", fig.cap="The use of different data types used to detect mounds and mound-like objects distributed by year between 2006 and 2021."}
library(dplyr)
library(ggplot2)
mounds_lit_2 <- read.csv(here::here('analysis/data/literature_analysis/burial_mounds_short.csv'))
#read as tibble
mounds_lit_2 <- dplyr::as_tibble(mounds_lit_2)
mounds_lit_2_filt <- mounds_lit_2[, c(3:7)]
all_combined_2 <- table(mounds_lit_2_filt$Year, mounds_lit_2_filt$OoI,
                      mounds_lit_2_filt$Data, mounds_lit_2_filt$Software_type,
                      mounds_lit_2_filt$access)
methods_table_2 <- stats::ftable(all_combined_2)
methods_table_df2 <- as.data.frame(methods_table_2)
names(methods_table_df2) <- c("Year", "OoI", "Data", "Software_type", "access", "Freq")
ggplot(methods_table_df2, aes(fill=Data, y=Freq, x=Year)) +
  geom_bar(position="stack", stat="identity") +
  ylim(0, 7) +
  scale_fill_manual(values=morris:::peacock_palette) +
  ggtitle(expression(atop("Data types used in Automated Archaeological Remote Sensing", atop("between 2006 and 2021", "")))) +
  theme_light() +
  xlab("Year") +
  ylab("Number of studies")
```
When taking the points ‘Software’ and ‘Access’ into account, it has to be expressed that it is only a recent phenomenon that software and computation details have to be disclosed when publishing a study. Even though lately many journals require data and code availability statements, only a few studies provide openly accessible code and data: Orengo et al. 2020, and Niculiță 2020. In the first case the data and the code  are available using Google Earth Engine. In the latter case, the regulations of the local Cultural Heritage Management authorities require a signed form through the author of the study to be able to use the DEM on which the study was based on - nonetheless it can be accessed. Although with restrictions. 
Inspecting the information about the methodology details of the studies, nine cases have been identified (Figure 15): from not available (n/a) to workflow & code & data, many constellations can be observed. In many cases the workflow was published, in some cases only a flowchart. In this thesis as a workflow the clear explanation of the methodology in a chart form is defined (with a big probability of reproducibility if the observer knew the exact tools and software used or if those were made clear). As a flowchart on the other hand, a part of a workflow or a very schematized workflow was identified where only the main steps were arranged in chart form, thus making it impossible to trace back the specific steps and to reproduce the workflow or any part of it. Thus the only reproducible study, which published a really detailed workflow, the code and made the dataset - although restricted by certain rules - available is Niculiță 2020.

```{r Figure 15, echo=FALSE, fig.align='center', fig.cap="Access to any parts of  studies used to detect mounds and mound-like objects distributed by year between 2006 and 2021."}
library(dplyr)
library(ggplot2)
mounds_lit_2 <- read.csv(here::here('analysis/data/literature_analysis/burial_mounds_short.csv'))
#read as tibble
mounds_lit_2 <- dplyr::as_tibble(mounds_lit_2)
mounds_lit_2_filt <- mounds_lit_2[, c(3:7)]
all_combined_2 <- table(mounds_lit_2_filt$Year, mounds_lit_2_filt$OoI,
                      mounds_lit_2_filt$Data, mounds_lit_2_filt$Software_type,
                      mounds_lit_2_filt$access)
methods_table_2 <- stats::ftable(all_combined_2)
methods_table_df2 <- as.data.frame(methods_table_2)
names(methods_table_df2) <- c("Year", "OoI", "Data", "Software_type", "access", "Freq")
ggplot(methods_table_df2, aes(fill=access, y=Freq, x=Year)) +
  geom_bar(position="stack", stat="identity") +
  ylim(0, 7) +
  scale_fill_manual(values=morris:::strawberry_palette ) +
  ggtitle(expression(atop("Access to any parts of studies investigated", 
                     atop("between 2006 and 2021", "")))) +
  theme_light() +
  xlab("Year") +
  ylab("Number of studies")
```
As already noted, eCognition is considered “the” software for GeOBIA (Hossain - Chen 2019, 122) thus it is evident that many will choose this simpler solution. At the same time, it must be emphasised that the first analyses were carried out in R (Menze et al. 2006, Menze et al. 2007, Menze and Ur 2007), i.e. with open source software.. Using proprietary software not only marginalises researchers and institutions who/which can’t afford rather expensive software, but  it is also hard to comprehend the exact algorithm behind the software, and to understand to be able to apply it in another domain. It is also important to understand why certain tools or algorithms worked or did not work? This can only be done by creating reproducible workflows with open source software. In 2019 and 2020 more than 60% of the studies were conducted with FOSS  (Free and Open Source Software) software. This number is only increasing (Figure 16).

```{r Figure 16, echo=FALSE, fig.align='center', fig.cap="Software types of studies used to detect mounds and mound-like objects distributed by year between 2006 and 2021."}
library(dplyr)
library(ggplot2)
mounds_lit_2 <- read.csv(here::here('analysis/data/literature_analysis/burial_mounds_short.csv'))
#read as tibble
mounds_lit_2 <- dplyr::as_tibble(mounds_lit_2)
mounds_lit_2_filt <- mounds_lit_2[, c(3:7)]
all_combined_2 <- table(mounds_lit_2_filt$Year, mounds_lit_2_filt$OoI,
                      mounds_lit_2_filt$Data, mounds_lit_2_filt$Software_type,
                      mounds_lit_2_filt$access)
methods_table_2 <- stats::ftable(all_combined_2)
methods_table_df2 <- as.data.frame(methods_table_2)
names(methods_table_df2) <- c("Year", "OoI", "Data", "Software_type", "access", "Freq")
ggplot(methods_table_df2, aes(fill=Software_type, y=Freq, x=Year)) +
  geom_bar(position="stack", stat="identity") +
  ylim(0, 7) +
  scale_fill_manual(values=morris:::flowers_palette) +
  ggtitle(expression(atop("Software types of studies investigated", 
                     atop("between 2006 and 2021", "")))) +
  theme_light() +
  xlab("Year") +
  ylab("Number of studies")
```
This survey served the purpose to elaborate the development of Automated Analysis in Archaeological Remote Sensing, mainly with regard to the applied methods, the used software and access to information about the workflow. The aim was to show how little reproducible research has been published with regard to automated analyses and how much there is to be done in the future. Also, automated analysis in Archaeological Remote Sensing is being carried out on different scales with different algorithms, specialized to different research questions in mainly research contexts. This is also a reason why many critical voices see automated analysis methods as pastimes and not really something operational (see many AARGnews Editorials). To give way for the next chapter we can conclude that the results of automated analyses are compelling, but many studies start basically from the beginning, because when research is published without accompanying software, workflow, data and documented steps, it is a challenge and time consuming to understand, verify, expand and eventually surpass that research (Marwick 2017, 425). This is one reason why many research projects start from the beginning, with a new idea instead of building on the previous knowledge. Another point is that automated analysis methods in Archaeological Remote Sensing are still in their infancy (Opitz and Herrmann 2018, 30) and best practices have not yet been established. Nonetheless it has to be stated that automated analysis itself is not a goal, but a method, a means to an end to further research and thus reproducible or even replicable best practices would help shift the focus on further development of methods than on continuous recommencements.

Chapter II discussed the use of automated analysis methods in Archaeological Remote Sensing for the detection of burial mounds and structurally similar archaeological objects. It was demonstrated that only 2 out of 31 studies have disclosed workflow, code and data and are thus reproducible (see chapter III for explanation). As a reproducible study in the R environment Niculiță 2020 can be taken as the best example. It was also noted that even without the availability of code, there are workflows which are illustrated and also explained clearly enough that they can be reproduced, which on the other hand can take some time but is still possible to do when having enough experience with spatial tools. 
On this basis it was decided that the Geometric knowledge-based workflow ‘iMound’ (established by Freeland at al. 2016 and reused by Davis et al. 2019 and Rom et al. 2020) is going to be utilized in R to detect burial mounds in LiDAR data in this Master’s thesis to create a reproducible workflow. During the implementation of the workflow it became clear that on the basis of the geomorphometry of the Train Area it was necessary to include another method to be able to effectively detect burial mounds (this is discussed in depth in Chapter IV). Thus, in addition to ‘iMound’ also the reproducible workflow of Niculiță 2020, thus a GeOBIA method was used in this Master’s thesis. 

<!--chapter:end:02-Literature.Rmd-->

# The Necessity of a Paradigm Shift in Archaeological Remote Sensing practice by means of Tool-driven Automated Analysis

In Chapter II the arguments of reproducibility and replicability have been addressed regarding the accessibility of data, code and workflow of the investigated studies. It was demonstrated that only 2 out of 31 studies have disclosed all three elements and are reproducible. It is important to discuss the exact definition of both expressions. In this Master’s thesis mainly the definitions of Marwick 2017 are followed.
Reproducibility means that code and workflow of an analysis reproduces all results and figures in the respective publication from its original raw data. Replicability stands for the replication of the workflow (from data collection to data analysis) onto a new dataset. It was mentioned in the introduction that optimal reproducible open science would incorporate version controlled open code, clear workflows and open datasets or at least training datasets.

So then, how is the best way to implement and  guarantee reproducibility? Marwick 2017 outlined four general principles of reproducible research:
i) Data and code provenance, sharing and archiving (analogue to artifact provenience)
ii) Scripted analyses (for reproducibility and ideally replicability)
iii) Version control (transparency of decision points of any research and possibility of collaboration)
iv) Self-contained computational environments (sharing the computational environment of the analysis for replicability).

Pushing forward along this road, Marwick et al. 2018 propose R-packages as research compendia to organize transparent and reproducible research to approach the general principles laid out in 2017. Research compendia should organize files according to conventions: separate data, method and output (the latter being disposable because they can be reproduced) and define which exact computational environment was used for the analysis. Building an R package around a research project automatically forces one to keep the guidelines and conventions of package building which also provides quality control mechanisms.
Research compendia come in many forms and complexities, as Marwick et al. 2018 discusses. The author of this Master’s thesis experimented with a basic form of reproducible research compendium when analysing the finds of an Iron Age cemetery in Hungary using multivariate statistical analysis (Schneider 2020). The work was done basically in an R project with a fixed project structure which was uploaded in a github repository (https://github.com/keltoskytoi/Multivariate_Statistics_Szentloerinc). The repository contains an .Rproj file with the settings for the project, a folder called DATA for the raw data to be analyzed and not to be changed during the study, two .R files with the code used for the analysis in the study, a README.md file with basic information of the paper, thus the title and where to get it. An earlier study and research compendium from 2015, but already in a very mature form by Ben Marwick already shows the many of the elements of an optimal research compendium (listed in Figure 12), organized as an R package with the published compendium on figshare for the study Clarkson et al. 2015 which is also completely replicable: https://github.com/benmarwick/1989-excavation-report-Madjedbebe; https://figshare.com/articles/software/1989_excavation_report_Madjebebe/1297059
A recent use of a research compendium is Schmid 2019 with the compendium published at OSF. This study is also completely replicable:
(https://github.com/nevrome/cultrans.bronzeageburials.article2019, https://osf.io/b6np2/)
Based on the reproducibility of these studies and on the personal experience and motivation mentioned above, it was decided to create a research compendium for the Master’s thesis.

The optimal outline for a complex research compendium in an R environment is reproduced from Marwick et al. 2018, Figure 4:

```{r Figure 17, echo=FALSE, fig.align='center', out.width="50%", out.height="50%", fig.cap="Figure 17. Schematized modus operandi of the Random Forest algorithm."}
knitr::include_graphics('C:/Users/kelto/Documents/iSEGMound/analysis/figures/Figure_17.png')
```

This optimal research compendium outline is implemented in the R package rrtools (‘reproducible research tools’, https://github.com/benmarwick/rrtools) by Ben Marwick, which helps to write reproducible research papers, setting up the structure propagated in Marwick et al 2018. Although this Master’s thesis cannot give place to all of these desired steps and tools, it shall provide a reproducible workflow for burial mound detection using R.

R is an open-source, open-access statistical scripting language which can be used either through the command line or it’s GUI,  R Studio. It has been used in several scientific domains, and lately it is one of the most commonly used scripting languages in Archaeological Sciences (Schmidt and Marwick 2020, 18). The advantages of scripting languages support the four general principles of reproducible research of Marwick 2017 (see above) which are embodied in an optimal research compendium. The use of scripting languages (can) facilitate the use of Automated Analysis methods in Archaeological Remote Sensing, by offering a clear and logical semantic syntax, delivering a (shared diachronic semantic) ontological consistency throughout the research project and for future use.

Schmidt and Marwick 2020 – after discussing idea- and tool-driven revolutions in science – debate the role of tools in paradigm-shifts in Archaeology. Archaeology is in a  paradoxical situation: for one it is mainly an idea-driven discipline, but it has seen multiple tool-driven paradigm shifts (e.g. with Clarke's Analytical Archaeology and the development of Computational Archaeology). Computational Archaeology, Archaeological Remote Sensing and Remote Sensing itself are disciplines where change is mainly tool-driven, as we can see based on Chapter 2, which analysed 31 papers. But tools also ignite ideas, so there is no clear distinction, more a self-induction.

Before going to the next step, the concept of “tool-driven” has to be investigated more thoroughly. Schmidt and Marwick 2020 borrow the concept from Galison 1997, who elaborated on a tool-driven change in particle physics in the twentieth century, meaning tools like digital devices (for instance computers in the case of Archaeology). They see R (or similar open source programming languages) as one projection of a tool-driven revolution, including sharing reproducible and replicable code (Schmidt and Marwick 2020, 19). In my opinion we have to go further - the concept of tool-driven should become more mundane and tangible: automated analysis in Archaeological Remote Sensing has to become tool-driven in order to present a robust scientific practice for Archaeology, which means that reproducible workflows have to be created to do specific tasks, such as feature extraction, segmentation, which can then be developed further and be learned from. Automated analysis in Archaeological Remote Sensing should embrace tool-driven reproducible research to the fullest to make it possible to learn from each other and to build upon the experience of each other to develop ideas further.

One important issue still needs to be addressed. Lately it has been stressed (Strupler 2021) that not all openly published data are comparable: only because the raw data, especially if they are older projects which do not comply yet with the Berlin Declaration on Open Access to Knowledge in the Social Sciences and Humanities, is openly published and the exact methods are known, it does not automatically grant reproducibility (Strupler 2021, 2.). This emphasizes, that not only new data, reproducible workflows and best practices need to be created and published according to guidelines, but also legacy data from on-going, long-term excavations should be revised and curated and updated, to fit the FAIR principles 'Findability', 'Accessibility', 'Interoperability', and 'Reuse' (Haas and van Leusen 2020). It is clearly a problematic issue in this case, because often the authors might not be retractable. Thus reproduction of previous studies is a good way to correct, curate and update these datasets and the code and data is perfect for learning and teaching workflows but also to learn how to deal with possible errors (Strupler 2021, 15). It has to be pointed out that it cannot be expected to have complete consistency between a dataset processed in the original study using a GIS platform and then replicated using a scripting language. When using software other than a scripting language (where optimally all steps taken are documented), there are often steps one does not document or forge. An error in a dataset or analysis is a different matter and complicates reproducibility but should not have a negative connotation and should not be seen as a failure in the archaeological scientific community but treated with ‘full disclosure’, as a learning effect on how to make datasets and analysis better. The valid point is raised, that when publishing datasets and analysis there should be a responsible person to turn to (Strupler 2021, 16-17). This is even true when e.g. in a project the data is collected by a different person than the one who will do the analysis. Often crucial information is already missing when doing the analysis in the first place and this also needs to be disclosed clearly in the analysis (metadata in any form suitable for the project) and is not to be left out. In the case of datasets made available in an online repository, the owner of the repository or provider (uploader) of the dataset seems to be the logical person to make responsible if not disclosed otherwise. This can be of course problematic with legacy datasets.	

This comes together with the development of best practices and publishing datasets with workflows as mentioned before and fits perfectly in the wider picture of the Reproducible Research Culture (Nakoinz 2021, 63). Reanalysis studies are the perfect means to test reproducibility and the quality of data and metadata (as seen above).
Like Quantitative Archaeology, also Automated Archaeological Remote Sensing needs a paradigm shift from a closed and restrictive to a sustainable Open Science.

<!--chapter:end:03-Materials.Rmd-->

# Applied Mound Detection

In certain instances it was decided to use screenshot to be able make points clearer. It was planned to use mapview::mapview, but it does not knit nicely when exported as a PDF. 

<!--chapter:end:04-Methods.Rmd-->

# Results of the iSEGMound Workflow

In this Master’s thesis two data preparation methods (DTm and Multi-Scale Topographic Index) and two segmentation methods (Watershed and Region Growing) were used and compared. The four workflows were tested on the Train DTM and the Train Area to understand the relationship between the size of the area of investigation and the variable settings of the respective algorithms. The most effective workflow was chosen to be applied to the five Areas of Interests: AoI 1, AoI 2, AoI 3, AoI 4 and AoI 5.

First let's have glimpse on the morphometric derivative chosen, the Multi-Scale Topographic Index, on the example of the Train DTM: 

```{r Figure 67, echo=FALSE, fig.align='center', out.width="100%", out.height="100%", fig.cap="Multi-Scale Topographic Index of the Train DTM, Scale 1:4450."}
knitr::include_graphics('C:/Users/kelto/Documents/iSEGMound/analysis/figures/Figure_67.png')
```
As a reminder let's see where the burial mound groups Site ID 5 (black) and Site ID 35 (blue) are located in the Training DTM:  

```{r Figure 68, echo=FALSE, fig.align='center', out.width="50%", out.height="50%", fig.cap="Multi-Scale Topographic Index of the Train DTM with bruial mound groups Site ID 5 and 35. Scale 1:4450."}
knitr::include_graphics('C:/Users/kelto/Documents/iSEGMound/analysis/figures/Figure_68.png')
```
We know from Dobiat et al. 1994, that Site ID 35 was identified as two mounds. As in Chapter 4 discussed, the mounds visible in Figure 68 were possible to be identified on ground.  

# **5.1 Results of the Training DTM**

The workflows applied on the Training DTM are the following: 
5a_iSEG05_WS, 5b_iSEG05_mtpi_WS, 5c_iSEG05_RG, and 5d_iSEG05_mtpi_RG.

Let's plot the results of the Training DTM by segmentation.
Left the Watershed Segmentation based on a DTM (iSEG05_WS, orange segments) and on the SAGA MTPI (iSEG05_mtpi_WS, lilac segments). Right  the Region Growing Segmentation based on a DTM (iSEG05_RG, light blue) and on the SAGA MTPI (iSEG05_mtpi_RG, brown):

```{r Figure 69, echo=FALSE,fig.show='hold', fig.align = "default", out.width="50%", out.height="50%", fig.cap="iSEG WS in orange and iSEG mtpi WS in lilac nect to iSEG RG in light blue and iSEG mtpi RG in brown, Scale 1:4450."}
knitr::include_graphics('C:/Users/kelto/Documents/iSEGMound/analysis/figures/Figure_69_1.png')
knitr::include_graphics('C:/Users/kelto/Documents/iSEGMound/analysis/figures/Figure_69_2.png')
```

The first thing that catches the eyes is that both segmentation methods were able to detect Site ID 35, using the SAGA MTPI. Thus it is already clear from this early step on, that in the case of these scarcely preserved burial mounds it is useful to work with morphometric derivatives. When comparing the two segmentation methods, it is apparent, that Watershed segmentation produces more segments than Region Growing. 

# **5.2 Results of the Training Area**

Before discussing the results of the segmentations, first let's inspect Site ID 7 and Site ID 14. 

Site ID 7 is situated relatively near to the North of Site IDs 5 and 35. The group is constituted of 9 burials, roughly in an elongated line, counted from Southwest to Northeast. When inspecting the mounds, it can be seen that, similar to Site ID 5-9, these are also very near to the forestry commuting routes. Also they already show erosion (mound Site ID 7-5 to 9), mainly in road proximity. This situation has already worsened since 2009/2010, the collection date of the LiDAR data. This burial mound group is similarly preserved such as the average height of the mounds of Site ID 5.

Site ID 14 stretches a little further away to the South and consists of altogether 18 burials. This burial mound group spreads similarly elongated as Site ID 7, although a grouping can be made out in the center region of the group. What is striking about this group is, that many of the mounds - apart from mound 8, which is cut right at the middle - have been just missed or only slightly touched by service roads. The situation of burial mound Site ID 14-8 already indicated, that it is going to be hard to detect this mound properly, because it might be will be difficult to distinguish from the road which is cutting it.  

```{r Figure 70, echo=FALSE, fig.show='hold', fig.align = "default", out.width="50%", out.height="50%", fig.cap="Site ID 7, consituted of 9 burial mounds and Site ID 14, constituted of 18 burial mounds on the DTM, Scale 1:1200 and 1:3100."}
knitr::include_graphics('C:/Users/kelto/Documents/iSEGMound/analysis/figures/Figure_70_1.png')
knitr::include_graphics('C:/Users/kelto/Documents/iSEGMound/analysis/figures/Figure_70_2.png')
```

The workflows applied on the Training Area are the following: 
6a_iSEG05_WS_ta, 6b_iSEG05_mtpi_WS_ta, 6c_iSEG05_RG_ta, 6d_iSEG05_mtpi_RG_ta.

Because the Training Area is too big to really see details when plotting the whole, three plots are going to be displayed: one overview to understand the amount of segments and then the two areas containing burial mounds (Site IDs 5, 7 and 35 and Site ID 14) will be plotted next to each other to see the exact segmentation results. 

Inspecting first the results of the Watershed Segmentation of the Training Area, iSEG05_WS_ta (pink segments) and iSEG05_mtpi_WS_ta (teal segments) are plotted together. It is clearly visible from the overview, that the first impression of the Training DTM is reinforced: more segments are left over by using the SAGA MTPI, which fit to *min* to *max* descriptor range as the segments complying to the burial mound mask. This means on the other hand of course more segments to check, but also more possibility to find previously not known mounds. This will be investigated in the Discussion.  

```{r Figure 71, echo=FALSE, fig.align='center', out.width="50%", out.height="50%", fig.cap="Plotting iSEG WS ta and iSEG mtpi WS ta on the DTM, Scale 1:18000."}
knitr::include_graphics('C:/Users/kelto/Documents/iSEGMound/analysis/figures/Figure_71.png')
```

When "zooming" in to the two areas (Figure 73) containing burial mounds, we can see the following: 
The Northern are (first image of Figure 74) demonstrates again the advantage of using MSTPI: the Site ID 35 is detected by the iSEG mtpi WS workflow, and also a second possible mound, which was only in the profile very slightly visible. Site ID 9 was also detected (in green), although unknowingly: only after the Whitebox MSTPI was checked against Dobiat et al. 1994, became clear that that segment might be Site ID 9. This workflow is better in detecting mounds in this area than the iSEG WS workflow, which missed Site Id 7-5,7-6,7-7 and 7-9). 
Looking at the Southern area (second image of Figure 74), iSEG WS workflow detected from Site ID 14 3 mounds more (14-1, 14-8 and 14-11) than the iSEG mtpi WS workflow, which detected 14-3 (but not detected by iSEG WS).
Although a little less accurate in the southern area, the iSEG mtpi WS workflow is more successful. 

```{r Figure 72, echo=FALSE, fig.show='hold', out.width="50%", fig.align = "default", fig.cap="Plotting iSEG WS ta and iSEG mtpi WS ta on the DTM, Scale 1:3000."}
knitr::include_graphics('C:/Users/kelto/Documents/iSEGMound/analysis/figures/Figure_72_1.png')
knitr::include_graphics('C:/Users/kelto/Documents/iSEGMound/analysis/figures/Figure_72_2.png')
```

Considering the Region Growing Segmentation, the overview tells us, that after filtering generally less segments are left over, which fit to *min* to *max* descriptor range as the segments complying to the burial mound mask:

```{r Figure 73, echo=FALSE, fig.align='center', out.width="50%", out.height="50%", fig.cap="Plotting iSEG RG ta and iSEG mtpi RG ta on the DTM, Scale 1:18000."}
knitr::include_graphics('C:/Users/kelto/Documents/iSEGMound/analysis/figures/Figure_73.png')
```

Going into the details, iSEG_RG_ta is depicted in lime color and iSEG_mtpi_RG in grass green. It is again clear, that using the SAGA MTPI , Site ID 35 is detected, even if only the most visible one.
The iSEG RG workflow does not detect all mounds from Site ID 5 (5-2 is missing and 5-5 is minimally detected), although so far all workflows detected all mounds. In the case of Site ID 7, only 7-1 (at least a part of it), 7-2, 7-3 and 7-8 was detected. 
The iSEG mtpi RG workflow did detect all mounds from Site ID 5, but it failed to detect Site ID 7-4, 7-7 and 7-9.
Between the two workflows iSEG mtpi RG is the more successful. 

```{r Figure 74, echo=FALSE, fig.show='hold', out.width="50%", fig.align = "default", fig.cap="Plotting iSEG RG ta and iSEG mtpi RG ta on the DTM, Scale 1:3000."}
knitr::include_graphics('C:/Users/kelto/Documents/iSEGMound/analysis/figures/Figure_74_1.png')
knitr::include_graphics('C:/Users/kelto/Documents/iSEGMound/analysis/figures/Figure_74_2.png')
```

\newpage
# **5.3 Choosing the best fitting segmentation**

We have seen, that it is clear, that SAGA MTPI as morphometric data preparation methods clearly enhances even the less well visible burial mounds and delineates the mounds more naturally. The remaining question is: how to choose between Watershed and Region growing Segmentation? Which segmentation is better? Two different considerations were investigated: the archaeological decision and the statistical decision. 

From the archaeological point of view the aim is to detect as many burial mounds as possible. This can be of course broken down to the question if we want to find the exact shape of the mounds (in the case of the Training DTM and Training Area) or is the most important to detect as much as possible locations in any shape (e.g. just half or ¾ of a mound is detected) but to detect as many as possible of them. In the case of this Master's, the archaeological choice is definately iSEG_mtpi_WS. 

The only statistical measure which was found the most approximatively fitting is the *Jaccard Index* or *Intersection over Union*. This measure is used in Deep Learning as an evaluation metric to measure the accuracy of an object detection on the original data set. That is,  

```{r Figure 75, echo=FALSE, fig.align='center', out.width="50%", out.height="50%", fig.cap="Values of Intersection over Union (IoU) or 'Jaccard Index'. Source: https://towardsdatascience.com/intersection-over-union-iou-calculation-for-evaluating-an-image-segmentation-model-8b22e2e84686."}
knitr::include_graphics('C:/Users/kelto/Documents/iSEGMound/analysis/figures/Figure_75.png')
```

```{r Table 10, echo=FALSE}
table_10 <- read.csv(here::here('analysis/supplementary-materials/IoU_comparison.csv'))
knitr::kable(table_10, longtable = T, booktabs = TRUE,
  caption = "Demo table")
```

<!--chapter:end:05-Results.Rmd-->

# Discussion

After the technical review of studies which use automation to detect burial  mounds  and mound-like structures in Archaeological Remote Sensing data sets, the aim of this Master thesis was to detect burial mounds by using the most frequent and  easily reproducible methods in the repertoire. As already emphasized in Chapter II and IV, the most accessible workflow is iMound and the only one reproducible workflow in R is published and developed in R (Niculitca 2020). After detailing the framework of the thesis in Chapter III, chapter IV was dedicated to the iSEGMound workflow, the actual product of this Master’s thesis. 



Although the results of the segmentation(s) are not perfect (often the exact form of the burial mounds is not reached) they still offer a quite effective tool to filter the amount  of data to be examined. The input for the workflow can be either a DTM or a  MSTPI and from the results of the different workflows it is very clear, that the enhancement of the mounds leads to a better detection (see the case of burial mound group 35, where in the training DTM one and in the training area both mounds are visible), although the mounds can be definitely enhanced better.

Whitebox vs. SAGA 
Technical problems: not updated packages etc. 



Shape index is a tricky thing, because the same value can mean different forms

This means on the other hand of course more segments to check, but also more possibility to find previously not known mounds. This will be investigated in the Discussion.  

<!--chapter:end:06-Discussion.Rmd-->

# Conclusion

Was haben wir aus der Arbeit gelernt? Hat es funktioniert? Was nicht? Wieso? War es erfolgreich?

Without reproducibility it is hard to really understand and recreate workflows, thus a reproducible workflow like the one developed in this Master’s thesis can facilitate the understanding and utilization of automated analysis also by less technically trained archaeologists. It can also enable the joint further development by other specialists and also the reuse of parts of the workflow and knowledge. 

The archaeological significance of such a reproducible workflow is moreover the assistance in the analysis of archaeological big datasets not only for research purposes but also for the Cultural Heritage Management sector. Of course the human operator cannot be removed from the equation and has an integral part in providing the variable settings for the different functions in the workflow (as in the case of this Master's thesis), which can be generalized but the different amount of input data (number of tiles) calls for different variable settings which frequently have to be checked. 
Using iMound as the first step when looking for burial mounds but basically any archaeological objects which protrude above the ground reduces the amount of data needed to feed to the GeOBIA algorithm. Thus iMound could be used as a useful data extraction method as data preparation in projects with big areas to cover. 


<!--chapter:end:07-Conclusion.Rmd-->

# Bibliography

<!--chapter:end:08-Bibliography.Rmd-->

# Supplements

<!--chapter:end:09-Supplements.Rmd-->

# Colophon

This report was generated on `r Sys.time()` using the following computational environment and dependencies: 

```{r colophon, cache = FALSE}
# which R packages and versions?
if ("devtools" %in% installed.packages()) devtools::session_info()
```
The current Git commit details are:

```{r}
# what commit is this file at? 
if ("git2r" %in% installed.packages() & git2r::in_repository(path = ".")) git2r::repository(here::here())  
```

<!--chapter:end:10-Colophon.Rmd-->

---
title: "iSEGMound – a Reproducible Workflow for Mound Detection in LiDAR-derived DTMs"
subtitle: "Agnes Schneider"
author: 
- "Submitted in accordance with the requirements for the degree of Master of Science"
- "Philipps-University Marburg" 
- "Department of Physical Geography"

site: bookdown::bookdown_site

date: '16.09.2021'
output: 
    bookdown::pdf_book:
      df_print: kable
      latex_engine: lualatex
      fig_caption: yes
      reference_docx: "../templates/template.docx" # Insert path for the DOCX file
      pandoc_args:
      - --lua-filter=../templates/scholarly-metadata.lua
      - --lua-filter=../templates/author-info-blocks.lua
      - --lua-filter=../templates/pagebreak.lua
      fontsize: 12 pt
      toc: true
      toc-depth: 5
      number_sections: true
bibliography: "../templates/references.bib"
csl: "../templates/antiquity.csl" # Insert path for the bib-style
---

\newpage
```{r child = here::here("analysis", "thesis", "01-Intro.Rmd")}
```
\newpage
```{r child = here::here("analysis", "thesis", "02-Literature.Rmd")}
```
\newpage
```{r child = here::here("analysis", "thesis", "03-Materials.Rmd")}
```
\newpage
```{r child = here::here("analysis", "thesis", "04-Methods.Rmd")}
```
\newpage
```{r child = here::here("analysis", "thesis", "05-Results.Rmd")}
```
\newpage
```{r child = here::here("analysis", "thesis", "06-Discussion.Rmd")}
```
\newpage
```{r child = here::here("analysis", "thesis", "07-Conclusion.Rmd")}
```
\newpage
```{r child = here::here("analysis", "thesis", "08-Bibliography.Rmd")}
```
\newpage
```{r child = here::here("analysis", "thesis", "09-Colophon.Rmd")}
```

<!--chapter:end:Index.Rmd-->

---
title: " "
output:
    bookdown::pdf_book:
      df_print: kable
      latex_engine: lualatex
      number_sections: TRUE
geometry: "left = 2.5cm, right = 2cm, top = 2cm, bottom = 2cm"
fontsize: 12pt
header-includes:
  - \usepackage{float}
  - \usepackage{sectsty}
  - \usepackage{paralist}
  - \usepackage{setspace}\spacing{1.5}
  - \usepackage{fancyhdr}
  - \usepackage{lastpage}
  - \usepackage{dcolumn}
  - \usepackage{natbib}\bibliographystyle{agsm}
  - \usepackage[nottoc, numbib]{tocbibind}
bibliography: references.bib
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
options(tinytex.verbose = TRUE)
```
\newpage

\allsectionsfont{\centering}
\subsectionfont{\raggedright}
\subsubsectionfont{\raggedright}

\pagenumbering{gobble}

\begin{centering}

\vspace{3cm}

```{r uni_logo, echo=F, out.width="75%", out.height="75%",}
knitr::include_graphics('C:/Users/kelto/Documents/iSEGMound/analysis/figures/UMR-Logo_sw.png')
```

\vspace{1cm}

\Large
\bf Department of Geography

\vspace{1cm}

\Large

\doublespacing
\bf iSEGMound – a Reproducible Workflow for Mound Detection in LiDAR-derived  DTMs

\vspace{1 cm}

\normalsize
\singlespacing

by

\vspace{0.5 cm}

\Large

\bf AGNES SCHNEIDER \\
    Matriculation number: 

\vspace{1.5 cm}

in partial fulfilment of the requirement \\
for the degree of MSc in Physical Geography

\vspace{1.5 cm}

Supervisor: Dr. Christoph Reudenbach \\
Second Supervisor: Dr. Karsten Lambers, Leiden University

\vspace{1.5 cm}

\normalsize
mm yy

\end{centering}

\pagenumbering{roman}
\newpage

\begin{centering}

\bf Abstract

\end{centering}

\newpage

\centering
\raggedright
\newpage
\tableofcontents



\newpage

\pagenumbering{arabic}

```{r acknowledgements, child = '00-Acknowledgements.Rmd'}
```

\newpage

```{r intro, child = '01-Intro.Rmd'}
```

\newpage

```{r literature, child = '02-Literature.Rmd'}
```

\newpage

```{r materials, child = '03-Materials.Rmd'}
```

\newpage

```{r methods, child = '04-Methods.Rmd'}
```

\newpage

```{r results, child = '05-Results.Rmd'}
```

\newpage

```{r discussion, child = '06-Discussion.Rmd'}
```

\newpage

```{r conclusion, child = '07-Conclusion.Rmd'}
```

\newpage

```{r bibliography, child = '08-Bibliography.Rmd'}
```

\newpage

```{r supplements, child = '09-Supplements.Rmd'}
```

\newpage

```{r colophon, child = '10-Colophon.Rmd'}
```

<!--chapter:end:main.Rmd-->

---
title: "Title Goes Here"
author:
  - Agnes Schneider:
      email: euboia@gmail.com
      institute: [Philipps University Marburg, Department of Physical Geography]
      correspondence: true
institute:
  - UofO: Department of Physical Geography
date: "`r format(Sys.time(), '%d %B, %Y')`"
output: 
    bookdown::pdf_book:
      latex_engine: lualatex
      fig_caption: yes
      reference_docx: "../templates/template.docx" # Insert path for the DOCX file
      pandoc_args:
      - --lua-filter=../templates/scholarly-metadata.lua
      - --lua-filter=../templates/author-info-blocks.lua
      - --lua-filter=../templates/pagebreak.lua
bibliography: "../templates/references.bib"
csl: "../templates/antiquity.csl" # Insert path for the bib-style
abstract: |
  Text of abstract
keywords: |
  keyword 1; keyword 2; keyword 3
highlights: |
  These are the highlights. 
---

<!-- This is the format for text comments that will be ignored during renderings. Do not put R code in these comments because it will not be ignored. -->

<!-- With the following code you can access and display values from the yml header above. -->

Keywords: `r rmarkdown::metadata$keywords`

Highlights: `r rmarkdown::metadata$highlights`

<!-- The following code chunk defines some general settings how code chunks should behave. -->

```{r setup, echo = FALSE}
knitr::opts_chunk$set(
  collapse = TRUE,
  warning = FALSE,
  message = FALSE,
  echo = FALSE,
  comment = "#>",
  fig.path = "../figures/",
  dpi = 300
)
```

<!-- The actual document text starts here: -->

#I. Introduction

Here is a citation [@Marwick2017]

# Background

# Methods

# Results

<!-- Here's some example analysis code: -->

```{r get-data, eval = FALSE}
# Note the path that we need to use to access our data files when rendering this document
my_data <- read.csv(here::here('analysis/data/raw_data/my_csv_file.csv'))
```

```{r demo-plot, fig.cap="A plot of random numbers"}
plot(rnorm(10))
```

Figure \@ref(fig:demo-plot) shows how we can have a caption and cross-reference for a plot

```{r demo-inline-code}
x <- round(pi, 2)
```

Here is an example of inline code `r x` in the middle of a sentence. 

# Discussion

# Conclusion

# Acknowledgements

<!-- The following line inserts a page break  -->

\newpage

# References 

<!-- The following line ensures the references appear here for the MS Word or HTML output files, rather than right at the end of the document (this will not work for PDF files):  -->

<div id="refs"></div>

\newpage

### Colophon

This report was generated on `r Sys.time()` using the following computational environment and dependencies: 

```{r colophon, cache = FALSE}
# which R packages and versions?
if ("devtools" %in% installed.packages()) devtools::session_info()
```

The current Git commit details are:

```{r}
# what commit is this file at? 
if ("git2r" %in% installed.packages() & git2r::in_repository(path = ".")) git2r::repository(here::here())  
```

<!--chapter:end:Master_Thesis.Rmd-->

---
title: 'My Final College Paper'
author: 'Your R. Name'
date: 'May 20xx'
institution: 'Reed College'
division: 'Mathematics and Natural Sciences'
advisor: 'Advisor F. Name'
# If you have more two advisors, un-silence line 7
#altadvisor: 'Your Other Advisor'
department: 'Mathematics'
degree: 'Bachelor of Arts'
knit: bookdown::render_book
site: bookdown::bookdown_site

# The next two lines allow you to change the spacing in your thesis. You can 
# switch out \onehalfspacing with \singlespacing or \doublespacing, if desired.
header-includes:
    - \usepackage{setspace}\onehalfspacing

# This will automatically install the {remotes} package and {thesisdown}
# Change this to FALSE if you'd like to install them manually on your own.
params:
  'Install needed packages for {thesisdown}': True
  
# Remove the hashtag to specify which version of output you would like.
# Can only choose one at a time.
output:
  thesisdown::thesis_pdf: default 
#  thesisdown::thesis_gitbook: default         
#  thesisdown::thesis_word: default
#  thesisdown::thesis_epub: default

# If you are creating a PDF you'll need to write your preliminary content 
# (e.g., abstract, acknowledgements) below or use code similar to line 25-26 
# for the .RMD files. If you are NOT producing a PDF, delete or silence
# lines 25-39 in this YAML header.
abstract: '`r if(knitr:::is_latex_output()) paste(readLines(here::here("prelims", "00-abstract.Rmd")), collapse = "\n  ")`'
# If you'd rather include the preliminary content in files instead of inline
# like below, use a command like that for the abstract above.  Note that a tab 
# is needed on the line after the `|`.
acknowledgements: |
  I want to thank a few people.
dedication: |
  You can have a dedication here if you wish. 
preface: |
  This is an example of a thesis setup to use the reed thesis document class 
  (for LaTeX) and the R bookdown package, in general.
  
# Specify the location of the bibliography below
bibliography: bib/thesis.bib
# Download your specific csl file and refer to it in the line below.
csl: csl/apa.csl
lot: true
lof: true
---

<!--
Above is the YAML (YAML Ain't Markup Language) header that includes a lot of 
metadata used to produce the document.  Be careful with spacing in this header!

If you'd prefer to not include a Dedication, for example, simply delete the section entirely, or silence them (add # before each line). 

If you have other LaTeX packages you would like to include, delete the # before header-includes and list the packages after hyphens on new lines.

If you'd like to include a comment that won't be produced in your resulting file enclose it in a block like this.

If you receive a duplicate label error after knitting, make sure to delete the index.Rmd file and then knit again.
-->

```{r include_packages, include=FALSE}
# This chunk ensures that the thesisdown package is
# installed and loaded. This thesisdown package includes
# the template files for the thesis.
if (!require(remotes)) {
  if (params$`Install needed packages for {thesisdown}`) {
    install.packages("remotes", repos = "https://cran.rstudio.com")
  } else {
    stop(
      paste('You need to run install.packages("remotes")",
            "first in the Console.')
    )
  }
}
if (!require(thesisdown)) {
  if (params$`Install needed packages for {thesisdown}`) {
    remotes::install_github("ismayc/thesisdown")
  } else {
    stop(
      paste(
        "You need to run",
        'remotes::install_github("ismayc/thesisdown")',
        "first in the Console."
      )
    )
  }
}
library(thesisdown)
# Set how wide the R output will go
options(width = 70)
```

<!--
The acknowledgments, preface, dedication, and abstract are added into the PDF
version automatically by inputting them in the YAML at the top of this file.
Alternatively, you can put that content in files like 00--prelim.Rmd and
00-abstract.Rmd like done below.
-->



```{r eval=!knitr::is_latex_output(), child=here::here("prelims", "00--prelim.Rmd")}

```

```{r eval=!knitr::is_latex_output(), child=here::here("prelims", "00-abstract.Rmd")}

```

<!-- The {.unnumbered} option here means that the introduction will be 
"Chapter 0." You can also use {-} for no numbers on chapters.
-->

# Introduction {.unnumbered}

Welcome to the _R Markdown_ thesis template. This template is based on (and in many places copied directly from) the Reed College LaTeX template, but hopefully it will provide a nicer interface for those that have never used TeX or LaTeX before.  Using _R Markdown_ will also allow you to easily keep track of your analyses in **R** chunks of code, with the resulting plots and output included as well.  The hope is this _R Markdown_ template gets you in the habit of doing reproducible research, which benefits you long-term as a researcher, but also will greatly help anyone that is trying to reproduce or build onto your results down the road.

Hopefully, you won't have much of a learning period to go through and you will reap the benefits of a nicely formatted thesis.  The use of LaTeX in combination with _Markdown_ is more consistent than the output of a word processor, much less prone to corruption or crashing, and the resulting file is smaller than a Word file. While you may have never had problems using Word in the past, your thesis is likely going to be about twice as large and complex as anything you've written before, taxing Word's capabilities.  After working with _Markdown_ and **R** together for a few weeks, we are confident this will be your reporting style of choice going forward.

<!-- 
If you're still on the fence about using _R Markdown_, check out the resource
for newbies available at <https://rbasics.netlify.com>. 
-->

**Why use it?**

_R Markdown_ creates a simple and straightforward way to interface with the beauty of LaTeX.  Packages have been written in **R** to work directly with LaTeX to produce nicely formatting tables and paragraphs. In addition to creating a user friendly interface to LaTeX, _R Markdown_ also allows you to read in your data, to analyze it and to visualize it using **R** functions, and also to provide the documentation and commentary on the results of your project.  Further, it allows for **R** results to be passed inline to the commentary of your results.  You'll see more on this later.  

<!-- 
Having your code and commentary all together in one place has a plethora of 
benefits!
-->

**Who should use it?**

Anyone who needs to use data analysis, math, tables, a lot of figures, complex cross-references, or who just cares about the final appearance of their document should use _R Markdown_. Of particular use should be anyone in the sciences, but the user-friendly nature of _Markdown_ and its ability to keep track of and easily include figures, automatically generate a table of contents, index, references, table of figures, etc. should make it of great benefit to nearly anyone writing a thesis project.

**For additional help with bookdown** 

Please visit [the free online bookdown reference guide](https://bookdown.org/yihui/bookdown/).

<!--chapter:end:test_index.Rmd-->

